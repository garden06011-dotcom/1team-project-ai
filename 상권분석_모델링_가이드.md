# 📊 상권 점수 예측 모델 가이드

이 문서는 상권 점수 예측 모델의 전체 프로세스를 쉽게 이해할 수 있도록 정리한 가이드입니다.

---

## 🎯 우리가 해결하려는 문제

**"사용자가 특정 구와 임대료를 입력하면, 그 조건에서 가장 좋은 상권을 추천해주자!"**

예를 들어:
- 사용자 입력: "강남구에서 임대료 5000만원으로 카페를 하고 싶어요"
- 모델 출력: "대치동(92점), 개포1동(87점), 일원동(85점) 순으로 추천합니다"

---

## 📋 전체 프로세스 한눈에 보기

```
1단계: Y값 생성 → 상권 점수 계산 (0~100점)
2단계: X변수 생성 → 예측에 사용할 특성 준비
3단계: 모델 학습 → LightGBM으로 학습
4단계: 예측 → 사용자 입력으로 상권 추천
```

---

## 1️⃣ Y값(목표 변수): 상권 점수는 어떻게 계산하나요?

### 핵심 개념

**"같은 구, 같은 임대료 구간에서 얼마나 좋은 입지인가?"**

→ 절대적인 점수가 아닌 **상대적인 점수** (0~100점)

### 왜 상대 점수를 사용하나요?

```
❌ 절대 점수 방식:
   강남구 대치동: 매출 130억 → 90점
   도봉구 쌍문동: 매출 20억 → 20점
   → 문제: 임대료가 다르면 비교가 불공평!

✅ 상대 점수 방식:
   강남구 고임대료 구간에서: 대치동 90점
   도봉구 저임대료 구간에서: 쌍문동 85점
   → 해결: 같은 조건끼리만 비교!
```

### 계산 단계

#### **Step 1: 기본 지표 계산**

두 가지 핵심 지표를 계산합니다:

1. **매출 효율** = 분기 매출 ÷ 임대료
   - "임대료 대비 얼마나 잘 버는가?"

2. **성장률** = (현재 매출 - 2년 전 매출) ÷ 2년 전 매출
   - "미래 성장 가능성이 있는가?"

#### **Step 2: 임대료 구간 나누기**

전국의 임대료를 5개 구간으로 분류합니다:

| 구간 | 임대료 범위 |
|------|------------|
| 저가 | ~3000만원 |
| 중저가 | 3000~5000만원 |
| 중고가 | 5000~7000만원 |
| 고가 | 7000~1억원 |
| 초고가 | 1억원~ |

#### **Step 3: 그룹별 정규화 (0~1)**

**같은 구 + 같은 임대료 구간 + 같은 연도** 내에서만 비교합니다.

- 그룹 내 최소값 → 0점
- 그룹 내 최대값 → 1점
- 나머지 → 0~1 사이 값

#### **Step 4: 최종 점수 계산 (0~100점)**

```
Y_점수 = (매출효율 정규화 × 0.5 + 성장률 정규화 × 0.2 + 경쟁 점수 × 0.3 ) × 100
```


### 실전 예시

#### 원본 데이터

| 행정구 | 행정동 | 임대료 | 카페 매출 | 2년 전 매출 |
|--------|--------|--------|----------|------------|
| 강남구 | 개포1동 | 5410만원 | 104억 | 95억 |
| 강남구 | 대치동 | 5200만원 | 130억 | 125억 |
| 강남구 | 삼성동 | 8000만원 | 180억 | 160억 |

#### 계산 과정

**1단계: 기본 지표**

| 행정동 | 매출/임대료 | 성장률 |
|--------|------------|--------|
| 개포1동 | 19.2 | 9.5% |
| 대치동 | 25.0 | 4.0% |
| 삼성동 | 22.5 | 12.5% |

**2단계: 임대료 구간 분류**

| 행정동 | 임대료 | 임대료 구간 |
|--------|--------|------------|
| 개포1동 | 5410만원 | 중고가 |
| 대치동 | 5200만원 | 중고가 |
| 삼성동 | 8000만원 | 고가 |

**3단계: 구간별 정규화**

중고가 구간 (개포1동, 대치동끼리 비교):

| 행정동 | 매출/임대료 | 정규화 | 성장률 | 정규화 |
|--------|------------|--------|--------|--------|
| 개포1동 | 19.2 | **0.00** (최소) | 9.5% | **1.00** (최대) |
| 대치동 | 25.0 | **1.00** (최대) | 4.0% | **0.00** (최소) |

고가 구간 (삼성동만 있음):

| 행정동 | 정규화 |
|--------|--------|
| 삼성동 | 0.50 (혼자라 중간값) |

**4단계: 최종 Y값**

| 행정동 | 계산식 | **최종 점수** |
|--------|--------|--------------|
| 개포1동 | 0.7×0 + 0.3×1.0 = 0.30 | **30점** |
| 대치동 | 0.7×1.0 + 0.3×0 = 0.70 | **70점** |
| 삼성동 | 0.7×0.5 + 0.3×0.6 | **53점** |

### 점수 해석

```
✅ 대치동 70점
   → 중고가 구간에서 매출 효율이 최고!
   → 성장률은 낮지만 안정적인 수익

⚠️ 개포1동 30점
   → 중고가 구간에서 매출 효율은 낮음
   → 성장률은 높아 미래 가능성 있음

📌 삼성동 53점
   → 고가 구간에서 혼자라 중간 점수
```

---

## 2️⃣ X변수(입력 변수): 예측에 무엇을 사용하나요?

### 전체 변수 구성 (총 13개)

```
정적 특성 (5개) → 변하지 않는 기본 정보
Lag Features (4개) → 과거 데이터
파생 변수 (2개) → 계산으로 만든 변수
시간 특성 (2개) → 시간 정보
```

### 상세 변수 설명

#### 1. 정적 특성 (5개)

| 변수명 | 설명 | 예시 |
|--------|------|------|
| 행정구_encoded | 구 이름 (숫자로 변환) | 5 (강남구) |
| 행정동_encoded | 동 이름 (숫자로 변환) | 23 (개포1동) |
| 임대료 | 사용자가 입력한 임대료 | 5000만원 |
| 주거인구 | 해당 지역 거주 인구 | 48,000명 |
| 직장인구 | 해당 지역 직장 인구 | 56,000명 |

#### 2. Lag Features (4개)

**"Lag"란?** 과거 시점의 데이터를 의미합니다.

| 변수명 | 설명 | 예시 |
|--------|------|------|
| {업종}_매출_lag1 | 1분기 전 매출 (3개월 전) | 100억 |
| {업종}_매출_lag4 | 4분기 전 매출 (1년 전) | 95억 |
| {업종}_점포수_lag1 | 1분기 전 점포 수 | 45개 |
| {업종}_점포수_lag4 | 4분기 전 점포 수 | 42개 |

**왜 Lag Features를 사용하나요?**

```
❌ 현재 매출을 X에 넣으면?
   → Data Leakage! (Y값 계산에 이미 사용됨)
   → 모델이 치팅하는 것과 같음

✅ 과거 매출을 X에 넣으면?
   → OK! 과거 정보로 미래를 예측
   → "작년에 잘 팔렸으면 올해도 잘 팔릴 것"
```

#### 3. 파생 변수 (2개)

기존 변수를 조합하여 새로운 의미를 만듭니다.

| 변수명 | 계산식 | 의미 |
|--------|--------|------|
| 인구밀도 | 주거인구 + 직장인구 | 유동인구 총량 |
| {업종}_점포당_매출 | 매출 ÷ 점포수 | 점포당 평균 매출 |

#### 4. 시간 특성 (2개)

| 변수명 | 설명 | 예시 |
|--------|------|------|
| 년도 | 연도 | 2024 |
| 분기 | 분기 (1~4) | 1 (1~3월) |

### 중요한 질문: "임대료를 Y 계산에 썼는데 X에도 써도 되나요?"

```
✅ 문제없습니다!

Y값 (종속변수):
  - "같은 임대료 구간 내" 상대 점수
  - 0~100점 (정규화된 값)

X값 (독립변수):
  - 실제 임대료 금액 (5000만원)
  - 절대값

→ 같은 데이터지만 "다른 정보"를 제공합니다!

예시:
  같은 임대료 5000만원이어도
  - 인구 많으면 → 높은 점수
  - 인구 적으면 → 낮은 점수

→ 모델은 임대료와 인구의 "조합"을 학습
```

---

## 3️⃣ Lag Features: 과거 데이터 활용법

### Lag Features란?

**"시간을 거슬러 올라간 데이터"**

```
현재: 2024년 1분기

lag1 = 1분기 전 = 2023년 4분기
lag4 = 4분기 전 = 2023년 1분기 (1년 전)
lag8 = 8분기 전 = 2022년 1분기 (2년 전)
```

### 왜 필요한가요?

시계열 데이터에서 **"과거가 미래를 예측"**합니다.

```
예시 1: 매출 추세
  - 1년 전 매출: 100억
  - 현재 매출: 110억
  → "성장 중이구나!" → 점수 상승 예측

예시 2: 점포 수 변화
  - 1년 전 점포: 30개
  - 현재 점포: 50개
  → "경쟁이 심해지고 있구나!" → 점수 하락 예측
```

### 생성 방법

```python
# 매출 lag 생성
df['카페_매출_lag1'] = df.groupby('행정동')['카페_분기매출'].shift(1)
df['카페_매출_lag4'] = df.groupby('행정동')['카페_분기매출'].shift(4)
```

**핵심:**
- `groupby('행정동')`: 각 동별로 따로 계산
- `shift(1)`: 1행 위로 이동 (1분기 전)
- `shift(4)`: 4행 위로 이동 (1년 전)

### 실전 예시

#### 원본 데이터

| 행정동 | 년도 | 분기 | 카페_매출 |
|--------|------|------|----------|
| 개포1동 | 2023 | 1 | 90억 |
| 개포1동 | 2023 | 2 | 95억 |
| 개포1동 | 2023 | 3 | 98억 |
| 개포1동 | 2023 | 4 | 100억 |
| 개포1동 | 2024 | 1 | 104억 |

#### Lag 적용 후

| 행정동 | 년도 | 분기 | 카페_매출 | lag1 | lag4 |
|--------|------|------|----------|------|------|
| 개포1동 | 2023 | 1 | 90억 | NaN | NaN |
| 개포1동 | 2023 | 2 | 95억 | 90억 | NaN |
| 개포1동 | 2023 | 3 | 98억 | 95억 | NaN |
| 개포1동 | 2023 | 4 | 100억 | 98억 | NaN |
| 개포1동 | 2024 | 1 | 104억 | **100억** | **90억** |

**2024년 1분기 데이터:**
- lag1 = 100억 (2023년 4분기)
- lag4 = 90억 (2023년 1분기, 1년 전)
- 성장률 = (104-90) / 90 = 15.6% 성장!

---

## 4️⃣ 모델: LightGBM

### LightGBM이란?

**"빠르고 정확한 머신러닝 알고리즘"**

- 의사결정나무를 여러 개 만들어서 예측
- Gradient Boosting 방식 (이전 실수를 보완하며 학습)
- Microsoft에서 개발한 최신 알고리즘

### 왜 LightGBM을 선택했나요?

#### 다른 모델과 비교

| 모델 | 성능 | 속도 | 해석 가능성 | 추천도 |
|------|------|------|------------|--------|
| LightGBM | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ✅ 1순위 |
| XGBoost | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ✅ 2순위 |
| Random Forest | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ | △ 3순위 |
| 선형회귀 | ⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ❌ 비추 |
| 딥러닝 | ⭐⭐⭐⭐ | ⭐ | ⭐ | ❌ 비추 |

#### LightGBM의 장점

| 특징 | 설명 | 장점 |
|------|------|------|
| 높은 성능 | Gradient Boosting | 예측 정확도 우수 |
| 빠른 속도 | Histogram 기반 | 대용량 데이터 가능 |
| 자동 처리 | 결측치 자동 처리 | 전처리 간단 |
| 해석 가능 | Feature Importance | 어떤 변수가 중요한지 알 수 있음 |
| 비선형 학습 | 트리 기반 | 복잡한 관계 학습 가능 |

### 하이퍼파라미터 설명

```python
model = lgb.LGBMRegressor(
    objective='regression',      # 회귀 문제 (점수 예측)
    n_estimators=500,            # 트리 500개 생성
    learning_rate=0.05,          # 학습 속도 (낮을수록 안정적)
    max_depth=6,                 # 트리 깊이 (깊을수록 복잡)
    num_leaves=31,               # 리프 노드 수 (많을수록 복잡)
    min_child_samples=20,        # 리프의 최소 샘플 수
    subsample=0.8,               # 80% 데이터만 사용 (과적합 방지)
    colsample_bytree=0.8,        # 80% 변수만 사용 (과적합 방지)
    random_state=42              # 재현성 (같은 결과 보장)
)
```

#### 각 파라미터의 의미

| 파라미터 | 값 | 의미 | 효과 |
|----------|---|------|------|
| n_estimators | 500 | 트리 개수 | 많을수록 정확하지만 느림 |
| learning_rate | 0.05 | 학습률 | 낮을수록 안정적, 높을수록 빠름 |
| max_depth | 6 | 트리 깊이 | 깊을수록 복잡한 패턴 학습 |
| subsample | 0.8 | 샘플 비율 | 과적합 방지 |

---

## 5️⃣ 전체 프로세스 코드

### Step 1: Y값 생성

```python
df_cafe = create_target_score(df, industry='카페')
# → Y_카페점수 컬럼 추가 (0~100점)
```

**결과:** 각 행정동에 상권 점수가 부여됨

### Step 2: X변수 생성

```python
df_cafe_features, le_gu, le_dong = create_features(df_cafe, industry='카페')
# → lag features, 파생 변수, 인코딩 추가
```

**결과:** 학습에 필요한 13개 변수 생성

### Step 3: 모델 학습

```python
model_cafe, importance = train_model(df_cafe_features, industry='카페')
# → LightGBM 학습
```

**출력 예시:**
```
Train: 1,200 rows
Test: 300 rows

성능 평가:
Train MAE: 3.24점
Test MAE: 4.87점
Train R²: 0.892
Test R²: 0.845

Top 5 중요 Feature:
1. 카페_매출_lag1 (35%)
2. 임대료 (22%)
3. 인구밀도 (15%)
4. 카페_점포수_lag1 (12%)
5. 행정구_encoded (8%)
```

### Step 4: 모델 저장

```python
import joblib

joblib.dump(model_cafe, 'model_카페.pkl')
joblib.dump(le_gu, 'encoder_gu_카페.pkl')
joblib.dump(le_dong, 'encoder_dong_카페.pkl')
```

### Step 5: 예측 (사용자 입력)

```python
# 사용자 입력: "강남구, 5000만원, 카페"
result = predict_for_user(
    df=df_cafe_features,
    model=model_cafe,
    user_gu='강남구',
    user_rent=5000,
    industry='카페'
)

# 결과:
# 1등: 대치동 (92점)
# 2등: 개포1동 (87점)
# 3등: 일원동 (85점)
```

---

## 🎯 핵심 포인트 정리

### 1. Y값 (목표 변수)

```
같은 구 + 같은 임대료 구간 내 상대 점수 (0~100점)
→ 매출 효율 70% + 성장률 30%
```

### 2. X변수 (입력 변수)

```
총 13개:
- 정적 특성 (5개): 구, 동, 임대료, 주거인구, 직장인구
- Lag Features (4개): 과거 매출, 과거 점포수
- 파생 변수 (2개): 인구밀도, 점포당 매출
- 시간 특성 (2개): 년도, 분기
```

### 3. Lag Features

```
과거 데이터로 현재를 예측
→ lag1 (1분기 전), lag4 (1년 전)
→ Data Leakage 방지
```

### 4. 모델

```
LightGBM (회귀)
→ 빠르고 정확하고 해석 가능
→ Feature Importance 제공
```

---

## 🔍 자주 묻는 질문 (FAQ)

### Q1. 왜 절대 점수가 아닌 상대 점수를 사용하나요?

**A:** 임대료가 다르면 비교가 불공평하기 때문입니다.

```
예시:
- 강남구 (임대료 1억): 매출 200억 → 좋은가?
- 도봉구 (임대료 2000만원): 매출 30억 → 좋은가?

→ 절대 금액으로는 비교 불가!
→ 같은 임대료 구간끼리만 비교해야 공평
```

### Q2. Y 계산에 쓴 변수를 X에 써도 되나요?

**A:** 네, 문제없습니다!

```
Y: 상대 점수 (정규화된 0~1 값)
X: 절대값 (실제 금액, 인구 수)
→ 다른 정보를 제공합니다
```

### Q3. 왜 현재 매출이 아닌 과거 매출(lag)을 사용하나요?

**A:** Data Leakage 방지를 위해서입니다.

```
현재 매출 → Y 계산에 이미 사용됨 → 치팅!
과거 매출 → Y와 독립적 → 정상적인 예측
```

### Q4. Feature Importance가 뭔가요?

**A:** 각 변수가 예측에 얼마나 중요한지 보여줍니다.

```
예시:
1. 과거 매출 (35%) → 가장 중요!
2. 임대료 (22%)
3. 인구밀도 (15%)
...

→ "과거 매출이 미래를 가장 잘 예측한다"
```

### Q5. MAE와 R²는 무엇인가요?

**A:** 모델 성능을 평가하는 지표입니다.

```
MAE (Mean Absolute Error):
- 평균적으로 몇 점 차이나는가?
- 낮을수록 좋음
- 예: MAE=5 → 평균 5점 차이

R² (결정계수):
- 모델이 얼마나 데이터를 설명하는가?
- 0~1 (높을수록 좋음)
- 예: R²=0.85 → 85% 설명
```

---

## 📚 다음 단계

1. **데이터 수집**: 상권 데이터 준비
2. **전처리**: 결측치 처리, 이상치 제거
3. **Y값 생성**: create_target_score() 실행
4. **X변수 생성**: create_features() 실행
5. **모델 학습**: train_model() 실행
6. **평가**: MAE, R² 확인
7. **튜닝**: 하이퍼파라미터 조정
8. **배포**: 모델 저장 및 API 구축

---

## 💡 팁

- 처음에는 작은 데이터로 시작하세요
- Feature Importance를 보고 중요한 변수를 파악하세요
- 과적합을 조심하세요 (Train과 Test 성능 차이 확인)
- 정기적으로 모델을 재학습하세요 (분기마다 업데이트)

---

**작성일:** 2025년
**버전:** 1.0
